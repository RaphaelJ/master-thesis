# Implementation details

## TileGx processor summary

The *TileGx* processor family has been developed by *Tilera*, until the company
was acquired by *EzChip* during the summer 2014.

The TileGx family has been declined in 9, 16, 36 and 72 cores models. These use
a proprietary 64 bits RISC architecture and run at a *1.2 Ghz frequency*.

Each core has a *32 KB L1 instruction cache*, a *32 KB L1 data cache* and a
*256 KB unified L2 cache*. There is no common L3 cache but L2 *caches can be
shared between cores* with an added latency. Details about the memory hierarchy
is given in the next paragraph.

These CPUs are designed to run network software. Consequently, they also have:

* *Co-prosessors* for packet analysis, network flow load-balancing, compression
  and encryption.
* *Integrated 10 Gbps Ethernet chipsets* to maximise efficiency, especially on
  small packets.

### Memory hierarchy

As said in the previous paragraph, the *TileGx* micro-architecture does not have
a shared L3 cache. Instead, core-local L2 caches can be accessed from other
cores, with an increased latency. The following table summarizes memory
subystems and their main properties *[Tile12]*.

| Memory          | Size               | Associativity | Latency (CPU cycles) |
| --------------- | ------------------ | ------------- | -------------------- |
| L1 instruction  | 32 KB              | 2 way         | 2                    |
| L1 data         | 32 KB              | 2 way         | 2                    |
| Local L2        | 256 KB             | 8 way         | 11                   |
| Shared L2       | 36 * 256 KB = 9 MB | 8 way         | 32 to 41             |
| RAM (DDR3-1600) | 16 GB      | Irrelevant    | 67 if page in TLB, 88 if not |

The TileGx architecture allows software developers to choose where memory pages
are cached in the L2 cache. Pages can be either cached in a specific core
(*homed pages*), or spread over the various cores (*hash-homed pages*).

## Abstracting the network stack

## No-copy interface

## Parallelisation and scalability

## Checksum

### Pre-computed checksums

## Micro optimisations



## Performance analysis and cost centres


